# **ETL Pipeline with Airflow & Docker**  
_Automating data extraction, transformation, and loading for wine quality analysis._  

## **Project Overview**  
This project is a fully automated ETL (Extract, Transform, Load) pipeline built with Apache Airflow and Docker. It processes a Wine Quality Dataset, cleaning and transforming the raw data before storing it in a PostgreSQL database for analysis. 

Manual data processing can be time-consuming and error-prone, this pipeline ensures reliable, repeatable, and scalable data ingestion and transformation.

---

## **How to Run This Project**
### **Clone the Repository**
```bash
git clone https://github.com/Ifyokoh/portfolio-projects.git
cd portfolio-projects/ETL-pipeline
```

### **Start the Docker Containers**
```bash
docker-compose up -d
```  
Access the **Airflow UI** at:  
ðŸ”— [http://localhost:8080](http://localhost:8080)  

---

## **Project Structure**
```
ETL-pipeline/
â”‚â”€â”€ dags/                    # Airflow DAGs
â”‚   â”œâ”€â”€ simple_etl_dag.py    # Main DAG definition
|â”€â”€ airflow-dockerfile       # Dockerfile for Airflow setup
|â”€â”€ init-db.sql              # SQL script to initialize PostgreSQL database
â”‚â”€â”€ docker-compose.yml       # Docker configuration
â”‚â”€â”€ requirements.txt         # dependencies
```
---

## **Key Features**
- Automated DAG Scheduling â€“ Airflow manages execution
- Containerized Workflow â€“ Runs in Docker, ensuring consistency
- Parallel Task Execution â€“ Scalable pipeline with Airflow Workers
- Database Storage â€“ Saves processed data into PostgreSQL